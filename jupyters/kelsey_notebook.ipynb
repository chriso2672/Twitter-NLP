{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stakeholder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apple as stakeholder and compare sentiment of its release vs. Google's at SXSW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "\n",
    "df = pd.read_csv('../data/tweets.csv', encoding = 'iso-8859-1')\n",
    "sw = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gets rid of company column\n",
    "tweets = df.drop('emotion_in_tweet_is_directed_at', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No emotion toward brand or product    5389\n",
       "Positive emotion                      2978\n",
       "Negative emotion                       570\n",
       "I can't tell                           156\n",
       "Name: is_there_an_emotion_directed_at_a_brand_or_product, dtype: int64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['is_there_an_emotion_directed_at_a_brand_or_product'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drops rows with unknown sentiment\n",
    "tweets = tweets[tweets['is_there_an_emotion_directed_at_a_brand_or_product'] != 'I can\\'t tell']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Renames column with sentiments as label and drops single nan row\n",
    "tweets['label'] = tweets['is_there_an_emotion_directed_at_a_brand_or_product']\n",
    "tweets = tweets.drop('is_there_an_emotion_directed_at_a_brand_or_product', axis = 1)\n",
    "tweets = tweets.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No emotion toward brand or product    0.602954\n",
       "Positive emotion                      0.333259\n",
       "Negative emotion                      0.063787\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.label.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    0.602954\n",
       "1    0.333259\n",
       "0    0.063787\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reassigns label\n",
    "tweets.label = tweets.label.map({'Negative emotion' : 0, 'Positive emotion': 1, \n",
    "                                 'No emotion toward brand or product': 2})\n",
    "\n",
    "tweets.label.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions to tokenize text\n",
    "import string\n",
    "\n",
    "#Replaces pos tags with lemmatize compatable tags\n",
    "def pos_replace(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "    \n",
    "#Makes list of punctuation to exclude, keeps certain symbols\n",
    "punct = list(string.punctuation)\n",
    "keep_punct = ['#', '?', '!', '@']\n",
    "punct = [p for p in punct if p not in keep_punct]\n",
    "\n",
    "#Used to filter out words leftover by twitter scrape\n",
    "common_tweet_words = ['#sxsw', 'rt']\n",
    "\n",
    "#Removes non-ASCII characters (aka emojis that cant be converted to original symbol)\n",
    "def remove_junk(tweet):\n",
    "    return ''.join([i if ord(i) < 128 else ' ' for i in tweet])\n",
    "    \n",
    "#TRY LOWERING/NOT LEMMATIZING AND SEE WHAT CHANGES\n",
    "def tweet_tokenizer(doc, stop_words = sw):\n",
    "    #Gets rid of links\n",
    "    doc = re.sub(r'http\\S+', '', doc)\n",
    "    doc = re.sub(r'www\\.[a-z]?\\.?(com)+|[a-z]+\\.(com)', '', doc)\n",
    "    #Gets rid of conversions made during scrapping\n",
    "    doc = re.sub(r'{link}', '', doc)\n",
    "    doc = re.sub(r'\\[video\\]', '', doc)\n",
    "    #Gets rid of weird characters\n",
    "    doc = remove_junk(doc)\n",
    "    #Tokenizes using NLTK Twitter Tokenizer\n",
    "    tweet_token = TweetTokenizer(strip_handles = True)\n",
    "    doc = tweet_token.tokenize(doc)\n",
    "    #Gets rid of leftover stopwords/punctuation/twitter meta-info\n",
    "    #doc = [w for w in doc if w.lower() not in sw]\n",
    "    doc = [w for w in doc if w.lower() not in common_tweet_words]\n",
    "    doc = [w for w in doc if w not in punct]\n",
    "    #Lemmatizes tokens\n",
    "    doc = pos_tag(doc)\n",
    "    doc = [(w[0], pos_replace(w[1])) for w in doc]\n",
    "    lemmatizer = WordNetLemmatizer() \n",
    "    doc = [lemmatizer.lemmatize(word[0], word[1]) for word in doc]\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@mention  - False Alarm: Google Circles Not Coming NowÛÒand Probably Not Ever? - {link} #Google #Circles #Social #SXSW\n",
      "\n",
      "\n",
      "['False', 'Alarm', 'Google', 'Circles', 'Coming', 'Probably', 'Ever', '?', '#Google', '#Circles', '#Social']\n"
     ]
    }
   ],
   "source": [
    "t = tweets.loc[38, 'tweet_text']\n",
    "test = tweet_tokenizer(t)\n",
    "print(t)\n",
    "print('\\n')\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Features with Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "def setup_three_subplots():\n",
    "    \"\"\"\n",
    "    It's hard to make an odd number of graphs pretty with just nrows\n",
    "    and ncols, so we make a custom grid. See example for more details:\n",
    "    https://matplotlib.org/stable/gallery/subplots_axes_and_figures/gridspec_multicolumn.html\n",
    "\n",
    "    We want the graphs to look like this:\n",
    "     [ ] [ ] [ ]\n",
    "       [ ] [ ]\n",
    "\n",
    "    So we make a 2x6 grid with 5 graphs arranged on it. 3 in the\n",
    "    top row, 2 in the second row\n",
    "\n",
    "      0 1 2 3 4 5\n",
    "    0|[|]|[|]|[|]|\n",
    "    1| |[|]|[|]| |\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(15,9))\n",
    "    fig.set_tight_layout(True)\n",
    "    gs = fig.add_gridspec(2, 4)\n",
    "    ax1 = fig.add_subplot(gs[0, :2]) # row 0, cols 0-1\n",
    "    ax2 = fig.add_subplot(gs[0, 2:4])# row 0, cols 2-3\n",
    "    #ax3 = fig.add_subplot(gs[0, 4:]) # row 0, cols 4-5\n",
    "    ax4 = fig.add_subplot(gs[1, 1:3])# row 1, cols 1-2\n",
    "    #ax5 = fig.add_subplot(gs[1, 3:5])# row 1, cols 3-4\n",
    "    return fig, [ax1, ax2, ax4]\n",
    "\n",
    "def plot_distribution_of_column_by_category(column, axes, title=\"Word Frequency for\"):\n",
    "    for index, category in enumerate([0, 1, 2]):\n",
    "        # Calculate frequency distribution for this subset\n",
    "        all_words = tweets[tweets[\"label\"] == index][column].explode()\n",
    "        freq_dist = FreqDist(all_words)\n",
    "        top_10 = list(zip(*freq_dist.most_common(10)))\n",
    "        tokens = top_10[0]\n",
    "        counts = top_10[1]\n",
    "\n",
    "        # Set up plot\n",
    "        ax = axes[index]\n",
    "        ax.hist(tokens, counts)\n",
    "\n",
    "        # Customize plot appearance\n",
    "        ax.set_title(f\"{title} {category}\")\n",
    "        ax.set_ylabel(\"Count\")\n",
    "        ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "        ax.tick_params(axis=\"x\", rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist\n",
    "\n",
    "all_words = []\n",
    "for tweet in tweets['tweet_text']:\n",
    "    all_words.extend(tweet_tokenizer(tweet))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11507"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = set(all_words)\n",
    "len(words)\n",
    "#print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Frequency of Top 20 Words in Text'}, xlabel='Samples', ylabel='Counts'>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist = FreqDist()\n",
    "for word in all_words:\n",
    "    fdist[word.lower()] += 1\n",
    "    \n",
    "fdist.plot(20, title = 'Frequency of Top 20 Words in Text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look for excessive puntuation - no go\n",
    "def punc_count(tweet):\n",
    "    punctuations = '!$%&()*+,-./:;<=>?[\\]^_`{|}~'\n",
    "    count = 0\n",
    "    for p in punctuations:\n",
    "        count += tweet.count(p)\n",
    "    return count\n",
    "\n",
    "#Look for excessive !/?'s' - no go\n",
    "def exc_que_count(tweet):\n",
    "    punctuation = '!?'\n",
    "    count = 0\n",
    "    for p in punctuation:\n",
    "        count += tweet.count(p)\n",
    "    return count\n",
    "\n",
    "#only periods\n",
    "def period_count(tweet):\n",
    "    punctuation = '.'\n",
    "    count = 0\n",
    "    for p in punctuation:\n",
    "        count += tweet.count(p)\n",
    "    return count\n",
    "\n",
    "#Ratio capital to length tweet\n",
    "def capital_letter_ratio(tweet):\n",
    "    capital_count = 0\n",
    "    for c in tweet:\n",
    "        if c.isupper():\n",
    "            capital_count += 1\n",
    "    return capital_count / len(tweet)\n",
    "\n",
    "#Repeating words - fix to be adjacent\n",
    "def any_repeats(tweet):\n",
    "    if len(set(tweet.split())) < len(tweet.split()):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0 \n",
    "    \n",
    "#Hashtag count\n",
    "def count_hash(tweet):\n",
    "    hashtag = re.findall(r'(#w[A-Za-z0-9]*)', tweet)\n",
    "    return len(hashtag)\n",
    "\n",
    "#Average word length\n",
    "def avg_length(tweet):\n",
    "    char = len(tweet)\n",
    "    word = len(tweet.split())\n",
    "    return char / word\n",
    "\n",
    "#Number of words\n",
    "def word_count(tweet):\n",
    "    return len(tweet.split())\n",
    "\n",
    "#Add in if tweet about Apple or Google?\n",
    "\n",
    "#Add in what service/product talk about?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get rid of bad data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    8936.000000\n",
       "mean       17.767793\n",
       "std         4.961420\n",
       "min         2.000000\n",
       "25%        14.000000\n",
       "50%        18.000000\n",
       "75%        21.000000\n",
       "max        33.000000\n",
       "Name: word_count, dtype: float64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['word_count'] = tweets['tweet_text'].apply(word_count)\n",
    "tweets['word_count'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5025</th>\n",
       "      <td>RT @mention</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tweet_text  label  word_count\n",
       "5025  RT @mention      2           2"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[tweets['word_count'] == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets[tweets['word_count'] != 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Apple',\n",
       " 'store',\n",
       " 'mall',\n",
       " 'Sunday',\n",
       " '10x',\n",
       " 'crowd',\n",
       " 'line',\n",
       " 'fake',\n",
       " 'need',\n",
       " 'fuck',\n",
       " 'dongle',\n",
       " 'Genius',\n",
       " 'let']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# negative = tweets[tweets.label == 0]\n",
    "# tweet_tokenizer(negative['tweet_text'][291])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Different Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['punc_count'] = tweets['tweet_text'].apply(punc_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweets.groupby('label')['exc_que_count'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# fig, axes = setup_three_subplots()\n",
    "# plot_distribution_of_column_by_category(\"punc_count\", axes, \"Freqency of Posts Containing Prices for\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Each Feature With Logreg Cause Visuals Are Hard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_test = tweets.drop('tweet_text', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_count</th>\n",
       "      <th>exc_que_count</th>\n",
       "      <th>punc_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7225</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5863</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3045</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2367</th>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7846</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7766</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3886</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8170</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3435</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6701 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      word_count  exc_que_count  punc_count\n",
       "7225           7              0           1\n",
       "5863          13              0           4\n",
       "3045          11              0           4\n",
       "2367          20              3           6\n",
       "7846          19              0           1\n",
       "...          ...            ...         ...\n",
       "7766          15              1           5\n",
       "3886          22              0           2\n",
       "1039          19              0           6\n",
       "8170          18              1           6\n",
       "3435          20              1           8\n",
       "\n",
       "[6701 rows x 3 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train test split\n",
    "y = tweets_test['label']\n",
    "X = tweets_test.drop('label', axis = 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 213)\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_count 0.06002538528680205\n",
      "punc_count 0.17909048047757065\n",
      "exc_que_count 0.19944959489690914\n",
      "capital_letter_ratio 0.2319134369654643\n",
      "any_repeats 0.08832240109620128\n",
      "count_hash 0.0\n",
      "avg_length 0.1428706650931737\n",
      "period_count 0.09832803618387893\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from imblearn.pipeline import Pipeline as imbpipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "features = imbpipeline(steps=[\n",
    "    ('smote', SMOTE(sampling_strategy = 'not majority', random_state=11)),\n",
    "    ('dtc', DecisionTreeClassifier(max_depth = 5, random_state = 213))\n",
    "])\n",
    "\n",
    "features.fit(X_train, y_train)\n",
    "for name, importance in zip(X_train.columns, features['dtc'].feature_importances_):\n",
    "    print(name, importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different Vectorizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train test split\n",
    "y = tweets['label']\n",
    "X = tweets.drop('label', axis = 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 213)\n",
    "\n",
    "col_labels = list(X_train.columns)\n",
    "col_labels.remove('tweet_text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Vectorize the words\n",
    "cv = CountVectorizer(encoding = 'iso-8859-1', lowercase = False, tokenizer = tweet_tokenizer)\n",
    "X_train_cv = cv.fit_transform(X_train['tweet_text'])\n",
    "\n",
    "#Scales the non-word columns\n",
    "X_train_nowords = X_train[col_labels]\n",
    "ss = StandardScaler()\n",
    "X_train_scaled = pd.DataFrame(ss.fit_transform(X_train_nowords),columns = X_train_nowords.columns, index = X_train.index)\n",
    "\n",
    "#Combines the scaled and vectorized data together\n",
    "X_train_cv_df = pd.DataFrame(X_train_cv.toarray(), columns=cv.get_feature_names(), index = X_train.index)\n",
    "X_train_final = pd.concat([X_train_cv_df, X_train_scaled], axis=1)\n",
    "\n",
    "#SMOTE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF_IDF Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(encoding = 'iso-8859-1', lowercase = False, tokenizer = tweet_tokenizer)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train['tweet_text'])\n",
    "\n",
    "#Scales the non-word columns\n",
    "X_train_nowords = X_train[col_labels]\n",
    "ss = StandardScaler()\n",
    "X_train_scaled = pd.DataFrame(ss.fit_transform(X_train_nowords),columns = X_train_nowords.columns, index = X_train.index)\n",
    "\n",
    "#Combines vectorized and scaled data together\n",
    "X_train_tfidf_df = pd.DataFrame(X_train_tfidf.toarray(), columns = tfidf.get_feature_names(), index = X_train.index)\n",
    "X_train_final = pd.concat([X_train_tfidf_df, X_train_scaled], axis=1)\n",
    "\n",
    "#SMOTE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Bayes - ONLY TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.8327115355917027\n",
      "Validation Score:0.6515432902601088\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#Train test split\n",
    "y = tweets['label']\n",
    "X = tweets['tweet_text']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 213)\n",
    "\n",
    "#Vectorize the words\n",
    "cv = CountVectorizer(encoding = 'iso-8859-1', lowercase = False, tokenizer = tweet_tokenizer)\n",
    "X_train_cv = cv.fit_transform(X_train)\n",
    "\n",
    "#Fit and print model scores\n",
    "first_pass = MultinomialNB()\n",
    "first_pass.fit(X_train_cv, y_train)\n",
    "print(\"Training Score:\", first_pass.score(X_train_cv, y_train))\n",
    "scores = np.mean(cross_val_score(first_pass, X_train_cv, y_train, cv=5))\n",
    "print(\"Validation Score:\" + str(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other models - can add other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IGNORE/TESTING AREA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IF WANT TRY PIPELINE/ADD FEATURE THINGY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "count_vec = FeatureUnion([\n",
    "        ('cv', CountVectorizer(encoding = 'iso-8859-1', lowercase = False, tokenizer = tweet_tokenizer))\n",
    "        #, add any feature creation things here\n",
    "    ])\n",
    "\n",
    "tfidf_vec = FeatureUnion([\n",
    "        ('tfidf', TfidfVectorizer(encoding = 'iso-8859-1', lowercase = False, tokenizer = tweet_tokenizer))\n",
    "        #, add any feature creation things here\n",
    "    ])\n",
    "\n",
    "first_pass = Pipeline(steps=[\n",
    "    ('vec', count_vec),\n",
    "    ('mnb', MultinomialNB())\n",
    "])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def punc_count(tweet):\n",
    "    punctuations = '!$%&()*+,-./:;<=>?[\\]^_`{|}~'\n",
    "    count = 0\n",
    "    for p in punctuations:\n",
    "        count += tweet.count(p)\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class PuncCount(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return pd.Series(X).apply(punc_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tweets['label']\n",
    "X = tweets['tweet_text']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 213)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "blocks[0,:] has incompatible row dimensions. Got blocks[0,1].shape[0] == 6701, expected 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-98-b8a1610a2539>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m ])\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mfirst_pass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training Score:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirst_pass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_pass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    328\u001b[0m         \"\"\"\n\u001b[1;32m    329\u001b[0m         \u001b[0mfit_params_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_fit_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m         with _print_elapsed_time('Pipeline',\n\u001b[1;32m    332\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[1;32m    290\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0;31m# Fit or load from cache the current transformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m             X, fitted_transformer = fit_transform_one_cached(\n\u001b[0m\u001b[1;32m    293\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m                 \u001b[0mmessage_clsname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Pipeline'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    738\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit_transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    960\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mXs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 962\u001b[0;31m             \u001b[0mXs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtocsr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    963\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m             \u001b[0mXs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/scipy/sparse/construct.py\u001b[0m in \u001b[0;36mhstack\u001b[0;34m(blocks, format, dtype)\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m     \"\"\"\n\u001b[0;32m--> 467\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/scipy/sparse/construct.py\u001b[0m in \u001b[0;36mbmat\u001b[0;34m(blocks, format, dtype)\u001b[0m\n\u001b[1;32m    586\u001b[0m                                                     \u001b[0mexp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbrow_lengths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m                                                     got=A.shape[0]))\n\u001b[0;32m--> 588\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbcol_lengths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: blocks[0,:] has incompatible row dimensions. Got blocks[0,1].shape[0] == 6701, expected 1."
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "\n",
    "count_vec = FeatureUnion([\n",
    "        ('punc', PuncCount()),\n",
    "        ('cv', CountVectorizer(encoding = 'iso-8859-1', lowercase = False, tokenizer = tweet_tokenizer))\n",
    "    ])\n",
    "\n",
    "first_pass = Pipeline(steps=[\n",
    "    ('preproc', count_vec),\n",
    "    #('ss', StandardSclaer()) - only if added features on diff scale\n",
    "    ('mnb', MultinomialNB())\n",
    "])\n",
    "\n",
    "first_pass.fit(X_train, y_train)\n",
    "print(\"Training Score:\", first_pass.score(X_train, y_train))\n",
    "scores = np.mean(cross_val_score(first_pass, X_train, y_train, cv=5))\n",
    "print(\"Validation Score:\" + str(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x6701 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 6479 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc = PuncCount()\n",
    "pc.fit(X_train)\n",
    "test = pc.transform(X_train)\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.47157140725264884\n",
      "Validation Score:0.4588858837802041\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.pipeline import Pipeline as imbpipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "y = tweets['label']\n",
    "X = tweets['tweet_text']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 213)\n",
    "\n",
    "baseline = imbpipeline(steps=[\n",
    "    ('preproc', CountVectorizer(encoding = 'iso-8859-1', lowercase = False, tokenizer = tweet_tokenizer)),\n",
    "    ('smote', SMOTE(sampling_strategy = 'not majority', random_state=11)),\n",
    "    ('dtc', DecisionTreeClassifier(random_state = 213, max_depth = 5))\n",
    "])\n",
    "\n",
    "baseline.fit(X_train, y_train)\n",
    "print(\"Training Score:\", baseline.score(X_train, y_train))\n",
    "scores = np.mean(cross_val_score(baseline, X_train, y_train, cv=5))\n",
    "print(\"Validation Score:\" + str(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterating Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>capital_letter_ratio</th>\n",
       "      <th>exc_que_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.118110</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.071942</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.088608</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.106870</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  label  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...      0   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...      1   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...      1   \n",
       "3  @sxsw I hope this year's festival isn't as cra...      0   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...      1   \n",
       "\n",
       "   capital_letter_ratio  exc_que_count  \n",
       "0              0.118110              1  \n",
       "1              0.071942              1  \n",
       "2              0.088608              0  \n",
       "3              0.024390              0  \n",
       "4              0.106870              0  "
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making final dataset\n",
    "tweets['capital_letter_ratio'] = tweets['tweet_text'].apply(capital_letter_ratio)\n",
    "tweets['exc_que_count'] = tweets['tweet_text'].apply(exc_que_count)\n",
    "tweets = tweets.drop('word_count', axis = 1)\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train test split\n",
    "y = tweets['label']\n",
    "X = tweets.drop('label', axis = 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 213)\n",
    "\n",
    "col_labels = list(X_train.columns)\n",
    "col_labels.remove('tweet_text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNB - No Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.8131622145948366\n",
      "Validation Score:0.6610949725644707\n"
     ]
    }
   ],
   "source": [
    "count_vec = ColumnTransformer([\n",
    "    ('cv', CountVectorizer(encoding = 'iso-8859-1', lowercase = False, tokenizer = tweet_tokenizer), 'tweet_text')],\n",
    "    #('scale', StandardScaler(), col_labels)],\n",
    "    remainder = 'passthrough')\n",
    "\n",
    "first = imbpipeline(steps=[\n",
    "    ('preproc', count_vec),\n",
    "    ('mnb', MultinomialNB())\n",
    "])\n",
    "\n",
    "first.fit(X_train, y_train)\n",
    "print(\"Training Score:\", first.score(X_train, y_train))\n",
    "scores = np.mean(cross_val_score(first, X_train, y_train, cv=5))\n",
    "print(\"Validation Score:\" + str(scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression - No Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.9292642889121027\n",
      "Validation Score:0.66288668514252\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "count_vec = ColumnTransformer([\n",
    "    ('cv', CountVectorizer(encoding = 'iso-8859-1', lowercase = False, tokenizer = tweet_tokenizer), 'tweet_text'),\n",
    "    ('scale', StandardScaler(), col_labels)],\n",
    "    remainder = 'passthrough')\n",
    "\n",
    "second = imbpipeline(steps=[\n",
    "    ('preproc', count_vec),\n",
    "    ('smote', SMOTE(sampling_strategy = 'not majority', random_state=11)),\n",
    "    ('logreg', LogisticRegression(random_state = 213, max_iter = 1000))\n",
    "])\n",
    "\n",
    "second.fit(X_train, y_train)\n",
    "print(\"Training Score:\", second.score(X_train, y_train))\n",
    "scores = np.mean(cross_val_score(second, X_train, y_train, cv=5))\n",
    "print(\"Validation Score:\" + str(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logreg - gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'logreg__C': 1.0, 'logreg__solver': 'lbfgs'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Creates parameters to test\n",
    "params = {\n",
    "    'logreg__C': [1.0, 1e3, 1e6],\n",
    "    'logreg__solver': ['lbfgs', 'saga']\n",
    "}\n",
    "\n",
    "#Fits gridsearch on model and prints out the best parameters\n",
    "search = GridSearchCV(second, param_grid = params, scoring = 'accuracy', cv = 3)\n",
    "search.fit(X_train, y_train)\n",
    "search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This would be where our tuned logreg went - if we had one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unknown tuned (?) model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNB - Gridsearch (lowercase/min max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/imblearn/pipeline.py\", line 277, in fit\n",
      "    Xt, yt, fit_params = self._fit(X, y, **fit_params)\n",
      "  File \"/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/imblearn/pipeline.py\", line 229, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/pipeline.py\", line 740, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/compose/_column_transformer.py\", line 531, in fit_transform\n",
      "    result = self._fit_transform(X, y, _fit_transform_one)\n",
      "  File \"/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/compose/_column_transformer.py\", line 458, in _fit_transform\n",
      "    return Parallel(n_jobs=self.n_jobs)(\n",
      "  File \"/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/pipeline.py\", line 740, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\", line 1213, in fit_transform\n",
      "    raise ValueError(\n",
      "ValueError: max_df corresponds to < documents than min_df\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/imblearn/pipeline.py\", line 277, in fit\n",
      "    Xt, yt, fit_params = self._fit(X, y, **fit_params)\n",
      "  File \"/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/imblearn/pipeline.py\", line 229, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/pipeline.py\", line 740, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/compose/_column_transformer.py\", line 531, in fit_transform\n",
      "    result = self._fit_transform(X, y, _fit_transform_one)\n",
      "  File \"/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/compose/_column_transformer.py\", line 458, in _fit_transform\n",
      "    return Parallel(n_jobs=self.n_jobs)(\n",
      "  File \"/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/pipeline.py\", line 740, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\", line 1213, in fit_transform\n",
      "    raise ValueError(\n",
      "ValueError: max_df corresponds to < documents than min_df\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'preproc__cv__lowercase': False,\n",
       " 'preproc__cv__max_df': 0.95,\n",
       " 'preproc__cv__min_df': 0}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creates parameters to test\n",
    "params = {\n",
    "    'preproc__cv__lowercase': [True, False],\n",
    "    'preproc__cv__min_df': [0, .05, .1],\n",
    "    'preproc__cv__max_df': [1, .95, .9]\n",
    "}\n",
    "\n",
    "#Fits gridsearch on model and prints out the best parameters\n",
    "search = GridSearchCV(first, param_grid = params, scoring = 'accuracy', cv = 3)\n",
    "search.fit(X_train, y_train)\n",
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.835397701835547\n",
      "Validation Score:0.6596012109474997\n"
     ]
    }
   ],
   "source": [
    "#Tuned MNB\n",
    "count_vec = ColumnTransformer([\n",
    "    ('cv', CountVectorizer(encoding = 'iso-8859-1', lowercase = False, tokenizer = tweet_tokenizer,\n",
    "                          max_df = .95), 'tweet_text')],\n",
    "    #('scale', StandardScaler(), col_labels)],\n",
    "    remainder = 'passthrough')\n",
    "\n",
    "tuned_mnb = imbpipeline(steps=[\n",
    "    ('preproc', count_vec),\n",
    "    ('mnb', MultinomialNB())\n",
    "])\n",
    "\n",
    "tuned_mnb.fit(X_train, y_train)\n",
    "print(\"Training Score:\", tuned_mnb.score(X_train, y_train))\n",
    "scores = np.mean(cross_val_score(tuned_mnb, X_train, y_train, cv=5))\n",
    "print(\"Validation Score:\" + str(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNB - gridsearch (ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'preproc__cv__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Creates parameters to test\n",
    "params = {\n",
    "    'preproc__cv__ngram_range': [(1,1), (1,2), (2,2)]\n",
    "}\n",
    "\n",
    "#Fits gridsearch on model and prints out the best parameters\n",
    "search = GridSearchCV(tuned_mnb, param_grid = params, scoring = 'accuracy', cv = 3)\n",
    "search.fit(X_train, y_train)\n",
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.9186688553947172\n",
      "Validation Score:0.6800486382405645\n"
     ]
    }
   ],
   "source": [
    "count_vec = ColumnTransformer([\n",
    "    ('cv', CountVectorizer(encoding = 'iso-8859-1', lowercase = False, tokenizer = tweet_tokenizer,\n",
    "                          max_df = .95, ngram_range = (1,2)), 'tweet_text')],\n",
    "    #('scale', StandardScaler(), col_labels)],\n",
    "    remainder = 'passthrough')\n",
    "\n",
    "ngram = imbpipeline(steps=[\n",
    "    ('preproc', count_vec),\n",
    "    ('mnb', MultinomialNB())\n",
    "])\n",
    "\n",
    "ngram.fit(X_train, y_train)\n",
    "print(\"Training Score:\", ngram.score(X_train, y_train))\n",
    "scores = np.mean(cross_val_score(ngram, X_train, y_train, cv=5))\n",
    "print(\"Validation Score:\" + str(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNB - gridsearch ngram max features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'preproc__cv__max_df': 0.5,\n",
       " 'preproc__cv__max_features': 8000,\n",
       " 'preproc__cv__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Creates parameters to test\n",
    "params = {\n",
    "    'preproc__cv__max_features': [None, 8000, 4000],\n",
    "    'preproc__cv__max_df': [.3, .5, .8],\n",
    "    'preproc__cv__ngram_range': [(1,1), (1,2), (2,2)]\n",
    "}\n",
    "\n",
    "#Fits gridsearch on model and prints out the best parameters\n",
    "search = GridSearchCV(ngram, param_grid = params, scoring = 'accuracy', cv = 3)\n",
    "search.fit(X_train, y_train)\n",
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.8288315176839278\n",
      "Validation Score:0.6718400169176488\n"
     ]
    }
   ],
   "source": [
    "count_vec = ColumnTransformer([\n",
    "    ('cv', CountVectorizer(encoding = 'iso-8859-1', lowercase = False, tokenizer = tweet_tokenizer,\n",
    "                          ngram_range = (1,1), max_df = .7, max_features = 8000), 'tweet_text')],\n",
    "    #('scale', StandardScaler(), col_labels)],\n",
    "    remainder = 'passthrough')\n",
    "\n",
    "test = imbpipeline(steps=[\n",
    "    ('preproc', count_vec),\n",
    "    ('mnb', MultinomialNB())\n",
    "])\n",
    "\n",
    "test.fit(X_train, y_train)\n",
    "print(\"Training Score:\", test.score(X_train, y_train))\n",
    "scores = np.mean(cross_val_score(test, X_train, y_train, cv=5))\n",
    "print(\"Validation Score:\" + str(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree - Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.9989553797940606\n",
      "Validation Score:0.6212522399189734\n"
     ]
    }
   ],
   "source": [
    "count_vec = ColumnTransformer([\n",
    "    ('cv', CountVectorizer(encoding = 'iso-8859-1', lowercase = False, tokenizer = tweet_tokenizer), 'tweet_text')],\n",
    "    #('scale', StandardScaler(), col_labels)],\n",
    "    remainder = 'passthrough')\n",
    "\n",
    "tree = imbpipeline(steps=[\n",
    "    ('preproc', count_vec),\n",
    "    ('smote', SMOTE(sampling_strategy = 'not majority', random_state=11)),\n",
    "    ('dtc', DecisionTreeClassifier(random_state = 213))\n",
    "])\n",
    "\n",
    "tree.fit(X_train, y_train)\n",
    "print(\"Training Score:\", tree.score(X_train, y_train))\n",
    "scores = np.mean(cross_val_score(tree, X_train, y_train, cv=5))\n",
    "print(\"Validation Score:\" + str(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dtc__max_depth': 30, 'dtc__min_samples_split': 2}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creates parameters to test\n",
    "params = {\n",
    "    'dtc__max_depth': [10, 20, 30],\n",
    "    'dtc__min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "#Fits gridsearch on model and prints out the best parameters\n",
    "search = GridSearchCV(tree, param_grid = params, scoring = 'accuracy', cv = 3)\n",
    "search.fit(X_train, y_train)\n",
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.7780928219668706\n",
      "Validation Score:0.6375170011241332\n"
     ]
    }
   ],
   "source": [
    "#min sample split = 5/max_depth = 20 has less overfitting\n",
    "tree = imbpipeline(steps=[\n",
    "    ('preproc', count_vec),\n",
    "    ('smote', SMOTE(sampling_strategy = 'not majority', random_state=11)),\n",
    "    ('dtc', DecisionTreeClassifier(random_state = 213, min_samples_split = 2, max_depth = 30))\n",
    "])\n",
    "\n",
    "tree.fit(X_train, y_train)\n",
    "print(\"Training Score:\", tree.score(X_train, y_train))\n",
    "scores = np.mean(cross_val_score(tree, X_train, y_train, cv=5))\n",
    "print(\"Validation Score:\" + str(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DTC w/ bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.9992538427100432\n",
      "Validation Score:0.6325916279898048\n"
     ]
    }
   ],
   "source": [
    "count_vec = ColumnTransformer([\n",
    "    ('cv', CountVectorizer(encoding = 'iso-8859-1', lowercase = False, tokenizer = tweet_tokenizer,\n",
    "                          ngram_range = (1,2)), 'tweet_text')],\n",
    "    #('scale', StandardScaler(), col_labels)],\n",
    "    remainder = 'passthrough')\n",
    "\n",
    "dtc_test = imbpipeline(steps=[\n",
    "    ('preproc', count_vec),\n",
    "    ('smote', SMOTE(sampling_strategy = 'not majority', random_state=11)),\n",
    "    ('dtc', DecisionTreeClassifier(random_state = 213))\n",
    "])\n",
    "\n",
    "dtc_test.fit(X_train, y_train)\n",
    "print(\"Training Score:\", dtc_test.score(X_train, y_train))\n",
    "scores = np.mean(cross_val_score(dtc_test, X_train, y_train, cv=5))\n",
    "print(\"Validation Score:\" + str(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dtc__criterion': 'gini', 'dtc__max_depth': 30}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creates parameters to test\n",
    "params = {\n",
    "    'dtc__max_depth': [20, 30, 40],\n",
    "    'dtc__criterion': ['entropy', 'gini']\n",
    "}\n",
    "\n",
    "#Fits gridsearch on model and prints out the best parameters\n",
    "search = GridSearchCV(dtc_test, param_grid = params, scoring = 'accuracy', cv = 3)\n",
    "search.fit(X_train, y_train)\n",
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.7130279062826443\n",
      "Validation Score:0.6245295891905128\n"
     ]
    }
   ],
   "source": [
    "count_vec = ColumnTransformer([\n",
    "    ('cv', CountVectorizer(encoding = 'iso-8859-1', lowercase = False, tokenizer = tweet_tokenizer,\n",
    "                          ngram_range = (1,2)), 'tweet_text')],\n",
    "    #('scale', StandardScaler(), col_labels)],\n",
    "    remainder = 'passthrough')\n",
    "\n",
    "dtc_test = imbpipeline(steps=[\n",
    "    ('preproc', count_vec),\n",
    "    ('smote', SMOTE(sampling_strategy = 'not majority', random_state=11)),\n",
    "    ('dtc', DecisionTreeClassifier(random_state = 213, max_depth = 30, max_features = 3000))\n",
    "])\n",
    "\n",
    "dtc_test.fit(X_train, y_train)\n",
    "print(\"Training Score:\", dtc_test.score(X_train, y_train))\n",
    "scores = np.mean(cross_val_score(dtc_test, X_train, y_train, cv=5))\n",
    "print(\"Validation Score:\" + str(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logreg with bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.7667512311595285\n",
      "Validation Score:0.5964791256246731\n"
     ]
    }
   ],
   "source": [
    "count_vec = ColumnTransformer([\n",
    "    ('cv', CountVectorizer(encoding = 'iso-8859-1', lowercase = False, tokenizer = tweet_tokenizer,\n",
    "                          ngram_range = (1,2), max_features = 1500), 'tweet_text'),\n",
    "    ('scale', StandardScaler(), col_labels)],\n",
    "    remainder = 'passthrough')\n",
    "\n",
    "logreg_worse = imbpipeline(steps=[\n",
    "    ('preproc', count_vec),\n",
    "    ('smote', SMOTE(sampling_strategy = 'not majority', random_state = 213)),\n",
    "    ('logreg', LogisticRegression(random_state = 213, max_iter = 1000))\n",
    "])\n",
    "\n",
    "logreg_worse.fit(X_train, y_train)\n",
    "print(\"Training Score:\", logreg_worse.score(X_train, y_train))\n",
    "scores = np.mean(cross_val_score(logreg_worse, X_train, y_train, cv=5))\n",
    "print(\"Validation Score:\" + str(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.9737352633935233\n",
      "Validation Score:0.6773597337696307\n"
     ]
    }
   ],
   "source": [
    "count_vec = ColumnTransformer([\n",
    "    ('cv', CountVectorizer(encoding = 'iso-8859-1', lowercase = False, tokenizer = tweet_tokenizer,\n",
    "                          ngram_range = (1,2)), 'tweet_text'),\n",
    "    ('scale', StandardScaler(), col_labels)],\n",
    "    remainder = 'passthrough')\n",
    "\n",
    "logreg_bi = imbpipeline(steps=[\n",
    "    ('preproc', count_vec),\n",
    "    ('smote', SMOTE(sampling_strategy = 'not majority', random_state = 213)),\n",
    "    ('logreg', LogisticRegression(random_state = 213, max_iter = 1000))\n",
    "])\n",
    "\n",
    "logreg_bi.fit(X_train, y_train)\n",
    "print(\"Training Score:\", logreg_bi.score(X_train, y_train))\n",
    "scores = np.mean(cross_val_score(logreg_bi, X_train, y_train, cv=5))\n",
    "print(\"Validation Score:\" + str(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'preproc__cv__max_features': None, 'preproc__cv__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creates parameters to test\n",
    "params = {\n",
    "    'preproc__cv__ngram_range': [(1,1), (1,2), (2,2)],\n",
    "    'preproc__cv__max_features': [None, 1000, 2000]\n",
    "}\n",
    "\n",
    "#Fits gridsearch on model and prints out the best parameters\n",
    "search = GridSearchCV(logreg_bi, param_grid = params, scoring = 'accuracy', cv = 3)\n",
    "search.fit(X_train, y_train)\n",
    "search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "class W2vVectorizer(object):\n",
    "    \n",
    "    def __init__(self, w2v):\n",
    "        # Takes in a dictionary of words and vectors as input\n",
    "        self.w2v = w2v\n",
    "        if len(w2v) == 0:\n",
    "            self.dimensions = 0\n",
    "        else:\n",
    "            self.dimensions = len(w2v[next(iter(glove))])\n",
    "            \n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "            \n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "            np.mean([self.w2v[w] for w in words if w in self.w2v]\n",
    "                   or [np.zeros(self.dimensions)], axis=0) for words in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "all_words = []\n",
    "for tweet in tweets['tweet_text']:\n",
    "    all_words.extend(tweet_tokenizer(tweet))\n",
    "    \n",
    "\n",
    "vocab_mix = set(all_words)\n",
    "test = []\n",
    "for word in vocab_mix:\n",
    "    test.append(word.lower())\n",
    "vocab = set(test)\n",
    "\n",
    "glove = {}\n",
    "with open('glove.6B.50d.txt', 'rb') as f:\n",
    "    for line in f:\n",
    "        parts = line.split()\n",
    "        word = parts[0].decode('utf-8')\n",
    "        if word in vocab:\n",
    "            vector = np.array(parts[1:], dtype=np.float32)\n",
    "            glove[word] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Random Forest', 0.6203548866778577),\n",
       " ('Support Vector Machine', 0.6028950725953165),\n",
       " ('Logistic Regression', 0.6178179295056399)]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "y = tweets['label']\n",
    "X = tweets['tweet_text']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)\n",
    "\n",
    "#Pick a Pipeline to try\n",
    "w2v_rfc = Pipeline([\n",
    "    ('Word2Vec', W2vVectorizer(glove)),\n",
    "    ('rf', RandomForestClassifier(random_state = 42))\n",
    "])\n",
    "\n",
    "w2v_svc = Pipeline([\n",
    "    ('Word2Vec Vectorizer', W2vVectorizer(glove)),\n",
    "    ('Support Vector Machine', SVC())\n",
    "])\n",
    "\n",
    "w2v_logreg = Pipeline([\n",
    "    ('Word2Vec', W2vVectorizer(glove)),\n",
    "    ('lr', LogisticRegression(max_iter = 1000, random_state = 42))\n",
    "])\n",
    "\n",
    "models = [('Random Forest', w2v_rfc),\n",
    "          ('Support Vector Machine', w2v_svc),\n",
    "          ('Logistic Regression', w2v_logreg)]\n",
    "\n",
    "scores = [(name, cross_val_score(model, X_train, y_train, cv = 3).mean()) for name, model, in models]\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rf__criterion': 'gini', 'rf__min_samples_split': 2, 'rf__n_estimators': 300}"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creates parameters to test\n",
    "params = {\n",
    "    'rf__n_estimators': [100, 300, 500],\n",
    "    'rf__min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "#Fits gridsearch on model and prints out the best parameters\n",
    "search = GridSearchCV(w2v_rfc, param_grid = params, scoring = 'accuracy', cv = 3)\n",
    "search.fit(X_train, y_train)\n",
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.995672287718251\n",
      "Validation Score:0.6236379623137112\n"
     ]
    }
   ],
   "source": [
    "w2v_tuned = Pipeline([\n",
    "    ('Word2Vec', W2vVectorizer(glove)),\n",
    "    ('rf', RandomForestClassifier(n_estimators = 300, random_state = 42))\n",
    "])\n",
    "\n",
    "w2v_tuned.fit(X_train, y_train)\n",
    "print(\"Training Score:\", w2v_tuned.score(X_train, y_train))\n",
    "scores = np.mean(cross_val_score(w2v_tuned, X_train, y_train, cv=5))\n",
    "print(\"Validation Score:\" + str(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Random Forest', 0.5834954722059961),\n",
       " ('Support Vector Machine', 0.39083807455060504),\n",
       " ('Logistic Regression', 0.4484387693723044)]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_rfc = imbpipeline([\n",
    "    ('Word2Vec', W2vVectorizer(glove)),\n",
    "    ('smote', SMOTE(sampling_strategy = 'not majority', random_state=11)),\n",
    "    ('rf', RandomForestClassifier(random_state = 42))\n",
    "])\n",
    "\n",
    "w2v_svc = imbpipeline([\n",
    "    ('Word2Vec Vectorizer', W2vVectorizer(glove)),\n",
    "    ('smote', SMOTE(sampling_strategy = 'not majority', random_state=11)),\n",
    "    ('Support Vector Machine', SVC())\n",
    "])\n",
    "\n",
    "w2v_logreg = imbpipeline([\n",
    "    ('Word2Vec', W2vVectorizer(glove)),\n",
    "    ('smote', SMOTE(sampling_strategy = 'not majority', random_state=11)),\n",
    "    ('lr', LogisticRegression(max_iter = 1000, random_state = 42))\n",
    "])\n",
    "\n",
    "models = [('Random Forest', w2v_rfc),\n",
    "          ('Support Vector Machine', w2v_svc),\n",
    "          ('Logistic Regression', w2v_logreg)]\n",
    "\n",
    "scores = [(name, cross_val_score(model, X_train, y_train, cv = 3).mean()) for name, model, in models]\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rf__min_samples_split': 2, 'rf__n_estimators': 800}"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creates parameters to test\n",
    "params = {\n",
    "    'rf__n_estimators': [500, 800, 1000],\n",
    "    'rf__min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "#Fits gridsearch on model and prints out the best parameters\n",
    "search = GridSearchCV(w2v_rfc, param_grid = params, scoring = 'accuracy', cv = 3)\n",
    "search.fit(X_train, y_train)\n",
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.995672287718251\n",
      "Validation Score:0.6279663205226663\n"
     ]
    }
   ],
   "source": [
    "w2v_tuned = Pipeline([\n",
    "    ('Word2Vec', W2vVectorizer(glove)),\n",
    "    ('rf', RandomForestClassifier(n_estimators = 800, min_samples_split = 2, random_state = 42))\n",
    "])\n",
    "\n",
    "w2v_tuned.fit(X_train, y_train)\n",
    "print(\"Training Score:\", w2v_tuned.score(X_train, y_train))\n",
    "scores = np.mean(cross_val_score(w2v_tuned, X_train, y_train, cv=5))\n",
    "print(\"Validation Score:\" + str(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting only Apple Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iPad                               946\n",
       "Apple                              661\n",
       "iPad or iPhone App                 470\n",
       "Google                             430\n",
       "iPhone                             297\n",
       "Other Google product or service    293\n",
       "Android App                         81\n",
       "Android                             78\n",
       "Other Apple product or service      35\n",
       "Name: emotion_in_tweet_is_directed_at, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['emotion_in_tweet_is_directed_at'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_labels = df[df['emotion_in_tweet_is_directed_at'].isna()]\n",
    "no_labels = no_labels.dropna(subset = ['tweet_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_list = []\n",
    "for tweet in no_labels['tweet_text']:\n",
    "    tweet_check = tweet.lower()\n",
    "    if ('iphone' in tweet_check) or ('ipad' in tweet_check) or ('apple' in tweet_check):\n",
    "        tweet_list.append(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipad = df[df['emotion_in_tweet_is_directed_at'] == 'iPad']\n",
    "apple = df[df['emotion_in_tweet_is_directed_at'] == 'Apple']\n",
    "mix = df[df['emotion_in_tweet_is_directed_at'] == 'iPad or iPhone App']\n",
    "iphone = df[df['emotion_in_tweet_is_directed_at'] == 'iPhone']\n",
    "apps = df[df['emotion_in_tweet_is_directed_at'] == 'Other Apple product or service']\n",
    "\n",
    "unlabeled_apple = df[df['tweet_text'].isin(tweet_list)]\n",
    "unlabeled_apple = unlabeled_apple.drop_duplicates(subset = 'tweet_text')\n",
    "\n",
    "final_df = pd.concat([ipad, apple, mix, iphone, apps, unlabeled_apple], axis = 0)\n",
    "\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No emotion toward brand or product    0.519993\n",
       "Positive emotion                      0.386466\n",
       "Negative emotion                      0.075629\n",
       "I can't tell                          0.017912\n",
       "Name: is_there_an_emotion_directed_at_a_brand_or_product, dtype: float64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df['is_there_an_emotion_directed_at_a_brand_or_product'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5527"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3408"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets) - len(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
